# Nginx configuration for web-crawler VPS deployment
# Serves archived websites with optimizations

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;

    # Gzip compression for faster delivery
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss;
    gzip_disable "msie6";

    # Cache settings for static assets
    map $sent_http_content_type $expires {
        default                    off;
        text/html                  epoch;
        text/css                   max;
        application/javascript     max;
        ~image/                    max;
    }

    expires $expires;

    # Upstream to crawler services
    upstream crawler_api {
        least_conn;
        server crawler:5000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    server {
        listen 80 default_server;
        server_name _;
        charset utf-8;

        # Security headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "no-referrer-when-downgrade" always;

        # Serve archived websites
        location /archive/ {
            alias /usr/share/nginx/html/archive/;
            autoindex on;
            autoindex_format html;

            # Cache static files
            location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
                expires 7d;
                add_header Cache-Control "public, immutable";
            }
        }

        # API endpoint (if needed)
        location /api/ {
            proxy_pass http://crawler_api;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "OK";
            add_header Content-Type text/plain;
        }

        # Status page
        location /status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            deny all;
        }

        # Default error pages
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;

        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }

    # HTTPS configuration (optional, requires SSL certificates)
    # Uncomment and configure for production with SSL
    #
    # server {
    #     listen 443 ssl http2 default_server;
    #     server_name example.com;
    #
    #     ssl_certificate /etc/nginx/ssl/cert.pem;
    #     ssl_certificate_key /etc/nginx/ssl/key.pem;
    #
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers HIGH:!aNULL:!MD5;
    #     ssl_prefer_server_ciphers on;
    #
    #     # ... rest of server config ...
    # }
    #
    # Redirect HTTP to HTTPS
    # server {
    #     listen 80;
    #     server_name example.com;
    #     return 301 https://$server_name$request_uri;
    # }
}
