      - name: Rewrite URLs to local paths (BeautifulSoup + CSS/JS)
        if: github.event.inputs.rewrite_links == 'true'
        continue-on-error: true
        run: |
          cd /tmp/target-repo
          
          DOMAIN="${{ steps.extract.outputs.domain }}"
          echo "üîó Rewriting URLs for domain: $DOMAIN (HTML, CSS, JS)"
          
          python3 << 'PYTHON'
          import os
          import re
          from pathlib import Path
          from urllib.parse import urlparse, urlunparse, urljoin
          
          try:
              from bs4 import BeautifulSoup
              HAS_BS4 = True
          except ImportError:
              HAS_BS4 = False
              print("‚ö†Ô∏è  BeautifulSoup not installed, using regex fallback")
          
          DOMAIN = "${{ steps.extract.outputs.domain }}"
          HTML_EXTS = {'.html', '.htm'}
          CSS_EXTS = {'.css'}
          JS_EXTS = {'.js'}
          modified_html = 0
          modified_css = 0
          modified_js = 0
          
          def convert_url(url, domain):
              """Convert absolute URL to relative path"""
              if url.startswith(f'http://{domain}') or url.startswith(f'https://{domain}'):
                  parsed = urlparse(url)
                  new_url = parsed.path
                  if parsed.query:
                      new_url += '?' + parsed.query
                  if parsed.fragment:
                      new_url += '#' + parsed.fragment
                  return new_url if new_url else '/'
              return url
          
          # ============================================
          # PROCESS HTML FILES
          # ============================================
          print(f"\nüìÑ Processing HTML files...")
          for root, dirs, files in os.walk('.'):
              if '.git' in dirs:
                  dirs.remove('.git')
              for file in files:
                  if Path(file).suffix.lower() in HTML_EXTS:
                      filepath = os.path.join(root, file)
                      try:
                          with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                              original = f.read()
                          
                          if HAS_BS4:
                              soup = BeautifulSoup(original, 'html.parser')
                              changes = 0
                              
                              # Add base href tag if not present (for relative path resolution)
                              if not soup.find('base'):
                                  head = soup.find('head')
                                  if head:
                                      base_tag = soup.new_tag('base', href='/')
                                      head.insert(0, base_tag)
                                      changes += 1
                              
                              # Process href attributes
                              for tag in soup.find_all(['a', 'link', 'base']):
                                  if tag.get('href'):
                                      url = tag['href']
                                      new_url = convert_url(url, DOMAIN)
                                      if new_url != url:
                                          tag['href'] = new_url
                                          changes += 1
                              
                              # Process src attributes
                              for tag in soup.find_all(['img', 'script', 'iframe', 'source']):
                                  if tag.get('src'):
                                      url = tag['src']
                                      new_url = convert_url(url, DOMAIN)
                                      if new_url != url:
                                          tag['src'] = new_url
                                          changes += 1
                              
                              # Process action attributes
                              for tag in soup.find_all('form'):
                                  if tag.get('action'):
                                      url = tag['action']
                                      new_url = convert_url(url, DOMAIN)
                                      if new_url != url:
                                          tag['action'] = new_url
                                          changes += 1
                              
                              # Process data attributes
                              for tag in soup.find_all('object'):
                                  if tag.get('data'):
                                      url = tag['data']
                                      new_url = convert_url(url, DOMAIN)
                                      if new_url != url:
                                          tag['data'] = new_url
                                          changes += 1
                              
                              if changes > 0:
                                  content = str(soup)
                                  with open(filepath, 'w', encoding='utf-8') as f:
                                      f.write(content)
                                  modified_html += 1
                          else:
                              # Fallback: regex
                              content = original
                              pattern = rf'((?:href|src|action|data)=["\'])https?://{re.escape(DOMAIN)}'
                              if re.search(pattern, content):
                                  content = re.sub(pattern, r'\1', content, flags=re.IGNORECASE)
                                  with open(filepath, 'w', encoding='utf-8') as f:
                                      f.write(content)
                                  modified_html += 1
                      except Exception as e:
                          print(f"‚ö†Ô∏è  Error processing HTML {filepath}: {e}")
          
          # ============================================
          # PROCESS CSS FILES
          # ============================================
          print(f"\nüé® Processing CSS files...")
          for root, dirs, files in os.walk('.'):
              if '.git' in dirs:
                  dirs.remove('.git')
              for file in files:
                  if Path(file).suffix.lower() in CSS_EXTS:
                      filepath = os.path.join(root, file)
                      try:
                          with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                              content = f.read()
                          
                          original = content
                          
                          # Rewrite URLs in url() declarations
                          pattern = rf'url\(["\']?https?://{re.escape(DOMAIN)}([^)"\']*)(?:["\'])?\)'
                          content = re.sub(pattern, r'url(\1)', content, flags=re.IGNORECASE)
                          
                          # Rewrite @import URLs
                          pattern = rf'@import\s+["\']https?://{re.escape(DOMAIN)}([^"\']*)["\']'
                          content = re.sub(pattern, r'@import "\1"', content, flags=re.IGNORECASE)
                          
                          # Rewrite @font-face src URLs
                          pattern = rf'src:\s*url\(["\']?https?://{re.escape(DOMAIN)}([^)"\']*)(?:["\'])?\)'
                          content = re.sub(pattern, r'src: url(\1)', content, flags=re.IGNORECASE)
                          
                          if content != original:
                              with open(filepath, 'w', encoding='utf-8') as f:
                                  f.write(content)
                              modified_css += 1
                      except Exception as e:
                          print(f"‚ö†Ô∏è  Error processing CSS {filepath}: {e}")
          
          # ============================================
          # PROCESS JS FILES
          # ============================================
          print(f"\nüîß Processing JavaScript files...")
          for root, dirs, files in os.walk('.'):
              if '.git' in dirs:
                  dirs.remove('.git')
              for file in files:
                  if Path(file).suffix.lower() in JS_EXTS:
                      filepath = os.path.join(root, file)
                      try:
                          with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                              content = f.read()
                          
                          original = content
                          
                          # Rewrite string URLs
                          pattern = rf'["\']https?://{re.escape(DOMAIN)}([^"\']*)["\']'
                          content = re.sub(pattern, r'"\1"', content, flags=re.IGNORECASE)
                          
                          if content != original:
                              with open(filepath, 'w', encoding='utf-8') as f:
                                  f.write(content)
                              modified_js += 1
                      except Exception as e:
                          print(f"‚ö†Ô∏è  Error processing JS {filepath}: {e}")
          
          print(f"\n‚úÖ URL Rewriting Complete:")
          print(f"   HTML files: {modified_html} modified")
          print(f"   CSS files: {modified_css} modified")
          print(f"   JS files: {modified_js} modified")
          print(f"   Total: {modified_html + modified_css + modified_js} files updated")
          PYTHON
