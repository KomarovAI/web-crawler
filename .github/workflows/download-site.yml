name: Download Site with Wget

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Start URL (e.g., https://example.com)'
        required: true
        type: string
      output_dir:
        description: 'Output directory for the archive'
        required: false
        type: string
        default: 'site_archive'
      max_pages:
        description: 'Maximum pages to crawl (optional, ignored in v2.1)'
        required: false
        type: string
        default: '500'
      use_selenium:
        description: 'Use Selenium for JavaScript (optional, future feature)'
        required: false
        type: string
        default: 'false'
      ignore_robots:
        description: 'Ignore robots.txt (optional, future feature)'
        required: false
        type: string
        default: 'true'
      resumeUrl:
        description: 'n8n webhook callback URL (optional)'
        required: false
        type: string
        default: ''

permissions:
  contents: read
  actions: read

jobs:
  download-site:
    name: Download Website
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget --version | head -1

      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Validate inputs
        id: validate
        run: |
          URL="${{ github.event.inputs.url }}"
          OUTPUT_DIR="${{ github.event.inputs.output_dir }}"
          
          # Apply defaults if empty
          URL=${URL:-"https://callmedley.com"}
          OUTPUT_DIR=${OUTPUT_DIR:-"site_archive"}
          
          # Validate URL format
          if [[ ! "$URL" =~ ^https?:// ]]; then
            echo "âŒ Error: URL must start with http:// or https://"
            exit 1
          fi
          
          # Sanitize output directory name
          SANITIZED_DIR=$(echo "$OUTPUT_DIR" | tr -cd '[:alnum:]_-')
          
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "output_dir=$SANITIZED_DIR" >> $GITHUB_OUTPUT
          
          echo "âœ… Inputs validated:"
          echo "   URL: $URL"
          echo "   Output Directory: $SANITIZED_DIR"
          echo ""
          echo "Note: max_pages, use_selenium, ignore_robots are stored for future use"

      - name: Download website with wget
        run: |
          python3 crawler.py "${{ steps.validate.outputs.url }}" "${{ steps.validate.outputs.output_dir }}"

      - name: Verify archive content
        id: verify
        run: |
          OUTPUT_DIR="${{ steps.validate.outputs.output_dir }}"
          DOMAIN=$(echo "${{ steps.validate.outputs.url }}" | sed -E 's|^https?://||' | sed -E 's|/.*||')
          ARCHIVE_PATH="$OUTPUT_DIR/$DOMAIN"
          
          echo "ðŸ“‚ Looking for archive at: $ARCHIVE_PATH"
          
          if [ ! -d "$ARCHIVE_PATH" ]; then
            echo "âŒ ERROR: Archive directory '$ARCHIVE_PATH' does not exist"
            echo ""
            echo "ðŸ“‹ Contents of '$OUTPUT_DIR':"
            ls -la "$OUTPUT_DIR" 2>/dev/null || echo "   (empty)"
            exit 1
          fi
          
          if [ -z "$(ls -A "$ARCHIVE_PATH")" ]; then
            echo "âŒ ERROR: Archive directory '$ARCHIVE_PATH' is empty"
            exit 1
          fi
          
          FILE_COUNT=$(find "$ARCHIVE_PATH" -type f | wc -l)
          DIR_SIZE=$(du -sh "$ARCHIVE_PATH" | cut -f1)
          
          echo "âœ… Verification successful!"
          echo "   Directory: $ARCHIVE_PATH"
          echo "   Total Files: $FILE_COUNT"
          echo "   Total Size: $DIR_SIZE"
          
          echo "upload_path=$ARCHIVE_PATH" >> $GITHUB_OUTPUT
          echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
          echo "dir_size=$DIR_SIZE" >> $GITHUB_OUTPUT

      - name: Upload site archive
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}
          path: ${{ steps.verify.outputs.upload_path }}
          retention-days: 30
          compression-level: 6
          if-no-files-found: error

      - name: Create job summary
        if: always()
        run: |
          echo "## âœ… Site Download Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **URL** | ${{ steps.validate.outputs.url }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Output Dir** | ${{ steps.validate.outputs.output_dir }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Files** | ${{ steps.verify.outputs.file_count }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Size** | ${{ steps.verify.outputs.dir_size }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Artifact** | ${{ steps.validate.outputs.output_dir }}-${{ github.run_id }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: Download successful âœ…" >> $GITHUB_STEP_SUMMARY

      - name: Send n8n callback (if provided)
        if: always() && github.event.inputs.resumeUrl != ''
        run: |
          RESUME_URL="${{ github.event.inputs.resumeUrl }}"
          JOB_STATUS="${{ job.status }}"
          RUN_ID="${{ github.run_id }}"
          DOMAIN="${{ steps.validate.outputs.url }}"
          
          if [ -n "$RESUME_URL" ]; then
            echo "ðŸ“¡ Sending callback to n8n: $RESUME_URL"
            
            PAYLOAD=$(cat <<EOF
{
  "status": "$JOB_STATUS",
  "run_id": "$RUN_ID",
  "domain": "$DOMAIN",
  "artifact_name": "${{ steps.validate.outputs.output_dir }}-$RUN_ID",
  "file_count": "${{ steps.verify.outputs.file_count }}",
  "size_mb": "${{ steps.verify.outputs.dir_size }}",
  "timestamp": "$(date -u +'%Y-%m-%dT%H:%M:%SZ')"
}
EOF
            )
            
            curl -X POST "$RESUME_URL" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" \
              --retry 3 \
              --retry-delay 5 \
              -w "\nâœ… Callback sent (HTTP %{http_code})\n" \
              || echo "âš ï¸ Callback failed (non-critical)"
          fi
