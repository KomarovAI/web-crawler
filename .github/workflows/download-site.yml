name: Download Site with Wget

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL to download'
        required: false
        type: string
        default: 'https://callmedley.com'
      output_dir:
        description: 'Output directory (default: site_archive)'
        required: false
        type: string
        default: 'site_archive'
      max_pages:
        description: 'Max pages to crawl (1-5000, default: 500)'
        required: false
        type: string
        default: '500'
      resumeUrl:
        description: 'Resume URL (n8n dispatchAndWait internal)'
        required: false
        type: string
        default: ''

permissions:
  contents: read
  actions: read

jobs:
  download-site:
    name: Download Website Archive
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout repository (LATEST)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          ref: main
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install wget
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget --version | head -1

      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Validate and prepare inputs
        id: validate
        run: |
          URL="${{ github.event.inputs.url }}"
          OUTPUT_DIR="${{ github.event.inputs.output_dir }}"
          MAX_PAGES="${{ github.event.inputs.max_pages }}"
          
          # Apply defaults
          URL=${URL:-"https://callmedley.com"}
          OUTPUT_DIR=${OUTPUT_DIR:-"site_archive"}
          MAX_PAGES=${MAX_PAGES:-"500"}
          
          echo ""
          echo "üìã Parsed inputs:"
          echo "   URL: $URL"
          echo "   Output Dir: $OUTPUT_DIR"
          echo "   Max Pages: $MAX_PAGES"
          echo ""
          
          # Validate URL
          if [[ ! "$URL" =~ ^https?:// ]]; then
            echo "‚ùå ERROR: URL must start with http:// or https://"
            echo "Got: $URL"
            exit 1
          fi
          
          # Validate max_pages (CRITICAL)
          if ! [[ "$MAX_PAGES" =~ ^[0-9]+$ ]]; then
            echo "‚ùå ERROR: max_pages must be numeric, got \"$MAX_PAGES\""
            exit 1
          fi
          
          if (( MAX_PAGES < 1 )) || (( MAX_PAGES > 5000 )); then
            echo "‚ùå ERROR: max_pages must be 1-5000, got $MAX_PAGES"
            exit 1
          fi
          
          # Sanitize directory name
          SANITIZED_DIR=$(echo "$OUTPUT_DIR" | tr -cd '[:alnum:]_-')
          if [ -z "$SANITIZED_DIR" ]; then
            SANITIZED_DIR="site_archive"
          fi
          
          echo "output_dir=$SANITIZED_DIR" >> $GITHUB_OUTPUT
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "max_pages=$MAX_PAGES" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Validation PASSED"
          echo "   URL: $URL"
          echo "   Output Dir: $SANITIZED_DIR"
          echo "   Max Pages: $MAX_PAGES"

      - name: Download website (with max_pages)
        id: download
        run: |
          echo ""
          echo "üöÄ Starting crawler with parameters:"
          echo "   URL: ${{ steps.validate.outputs.url }}"
          echo "   Output Dir: ${{ steps.validate.outputs.output_dir }}"
          echo "   Max Pages: ${{ steps.validate.outputs.max_pages }}"
          echo ""
          
          python3 crawler.py \
            "${{ steps.validate.outputs.url }}" \
            "${{ steps.validate.outputs.output_dir }}" \
            "${{ steps.validate.outputs.max_pages }}"

      - name: Verify archive
        id: verify
        if: always()
        run: |
          OUTPUT_DIR="${{ steps.validate.outputs.output_dir }}"
          DOMAIN=$(echo "${{ steps.validate.outputs.url }}" | sed -E 's|^https?://||' | sed -E 's|/.*||')
          ARCHIVE_PATH="$OUTPUT_DIR/$DOMAIN"
          
          echo ""
          echo "üîç Verifying archive at: $ARCHIVE_PATH"
          
          if [ ! -d "$ARCHIVE_PATH" ]; then
            echo "‚ö†Ô∏è WARNING: Archive directory not found at $ARCHIVE_PATH"
            echo "Listing $OUTPUT_DIR:"
            ls -la "$OUTPUT_DIR" 2>/dev/null || echo "Directory doesn't exist"
            exit 1
          fi
          
          if [ -z "$(ls -A "$ARCHIVE_PATH" 2>/dev/null)" ]; then
            echo "‚ùå ERROR: Archive directory is empty"
            exit 1
          fi
          
          FILE_COUNT=$(find "$ARCHIVE_PATH" -type f | wc -l)
          DIR_SIZE=$(du -sh "$ARCHIVE_PATH" | cut -f1)
          
          echo "‚úÖ Archive verified:"
          echo "   Files: $FILE_COUNT"
          echo "   Size: $DIR_SIZE"
          echo ""
          
          echo "upload_path=$ARCHIVE_PATH" >> $GITHUB_OUTPUT
          echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
          echo "dir_size=$DIR_SIZE" >> $GITHUB_OUTPUT

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}
          path: ${{ steps.verify.outputs.upload_path }}
          retention-days: 30
          compression-level: 6
          if-no-files-found: warn

      - name: Create summary
        if: always()
        run: |
          echo "## ‚úÖ Download Site Workflow" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Key | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **URL** | ${{ steps.validate.outputs.url }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Max Pages** | ${{ steps.validate.outputs.max_pages }} |" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ steps.verify.outputs.file_count }}" ]; then
            echo "| **Files Downloaded** | ${{ steps.verify.outputs.file_count }} |" >> $GITHUB_STEP_SUMMARY
            echo "| **Archive Size** | ${{ steps.verify.outputs.dir_size }} |" >> $GITHUB_STEP_SUMMARY
            echo "| **Status** | ‚úÖ Success |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| **Status** | ‚ö†Ô∏è Completed with warnings |" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Resume n8n execution (dispatchAndWait callback)
        if: always() && github.event.inputs.resumeUrl != ''
        run: |
          RESUME_URL="${{ github.event.inputs.resumeUrl }}"
          FILE_COUNT="${{ steps.verify.outputs.file_count }}"
          DIR_SIZE="${{ steps.verify.outputs.dir_size }}"
          STATUS="success"
          
          if [ -z "$FILE_COUNT" ]; then
            STATUS="failed"
            FILE_COUNT="0"
            DIR_SIZE="0"
          fi
          
          echo ""
          echo "üì° Sending callback to n8n: $RESUME_URL"
          echo "   Status: $STATUS"
          echo "   Files: $FILE_COUNT"
          echo "   Size: $DIR_SIZE"
          echo ""
          
          curl -X POST "$RESUME_URL" \
            -H "Content-Type: application/json" \
            -d "{
              \"status\": \"$STATUS\",
              \"files_count\": $FILE_COUNT,
              \"archive_size\": \"$DIR_SIZE\",
              \"url\": \"${{ steps.validate.outputs.url }}\",
              \"run_id\": \"${{ github.run_id }}\"
            }" \
            -v || echo "‚ö†Ô∏è Failed to send callback, but workflow completed"
