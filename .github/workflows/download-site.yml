name: Download Website Archive

concurrency:
  group: download-${{ github.event.inputs.url }}-${{ github.event.inputs.depth_level }}
  cancel-in-progress: true

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL to download (e.g., https://example.com)'
        required: false
        default: 'https://callmedley.com'
        type: string
      depth_level:
        description: 'Crawl depth: 1=homepage, 2=+children (default), 3=+grandchildren, 4=very deep'
        required: false
        default: '2'
        type: choice
        options:
          - '1'
          - '2'
          - '3'
          - '4'
      output_dir:
        description: 'Output directory name (alphanumeric, dash, underscore only)'
        required: false
        default: 'site_archive'
        type: string
      resumeUrl:
        description: 'N8N webhook URL for callback (auto-filled by N8N)'
        required: false
        type: string

permissions: {}

jobs:
  download:
    name: Download Website Archive
    runs-on: ubuntu-24.04
    timeout-minutes: 60

    steps:
      - name: Install dependencies
        run: |
          set -e
          sudo apt-get update -qq
          sudo apt-get install -y wget
          echo "‚úÖ Dependencies installed"

      - name: Validate inputs
        id: validate
        env:
          INPUT_URL: ${{ github.event.inputs.url || 'https://callmedley.com' }}
          INPUT_DEPTH: ${{ github.event.inputs.depth_level || '2' }}
          INPUT_OUTPUT: ${{ github.event.inputs.output_dir || 'site_archive' }}
        run: |
          set -e

          # Validate URL
          if [[ ! "$INPUT_URL" =~ ^https?:// ]]; then
            echo "‚ùå URL must start with http" "// or https" "//"
            exit 1
          fi

          # Validate depth_level
          if ! [[ "$INPUT_DEPTH" =~ ^[0-9]+$ ]] || (( INPUT_DEPTH < 1 )) || (( INPUT_DEPTH > 4 )); then
            echo "‚ùå depth_level must be 1-4"
            exit 1
          fi

          # Get level description
          case $INPUT_DEPTH in
            1) LEVEL_DESC="homepage only" ;;
            2) LEVEL_DESC="homepage + children (default)" ;;
            3) LEVEL_DESC="homepage + 2 levels deep" ;;
            4) LEVEL_DESC="very deep crawl" ;;
          esac

          # Sanitize directory
          SANITIZED_DIR=$(echo "$INPUT_OUTPUT" | tr -cd '[:alnum:]_-')
          SANITIZED_DIR=${SANITIZED_DIR:-site_archive}

          echo "output_dir=$SANITIZED_DIR" >> $GITHUB_OUTPUT
          echo "url=$INPUT_URL" >> $GITHUB_OUTPUT
          echo "depth_level=$INPUT_DEPTH" >> $GITHUB_OUTPUT
          echo "level_description=$LEVEL_DESC" >> $GITHUB_OUTPUT
          
          DOMAIN=$(echo "$INPUT_URL" | sed 's|https://||g' | sed 's|http://||g' | cut -d'/' -f1)
          echo "üìã Input validated" "$DOMAIN | depth=$INPUT_DEPTH | $LEVEL_DESC"

      - name: Download site with wget
        id: download
        timeout-minutes: 45
        env:
          URL: ${{ steps.validate.outputs.url }}
          OUTPUT_DIR: ${{ steps.validate.outputs.output_dir }}
          DEPTH: ${{ steps.validate.outputs.depth_level }}
        run: |
          set -e
          mkdir -p "$OUTPUT_DIR"
          
          echo "üåê Starting download from" "$URL"
          START_TIME=$(date +%s)
          
          wget --recursive \
            --level="$DEPTH" \
            --page-requisites \
            --convert-links \
            --adjust-extension \
            --no-parent \
            --directory-prefix="$OUTPUT_DIR" \
            --timeout=30 \
            --tries=3 \
            --wait=2 \
            --random-wait \
            --user-agent="Mozilla/5.0 (compatible; ArchiveBot/1.0; +https://github.com/KomarovAI/web-crawler)" \
            --reject-regex='\?.*' \
            "$URL" 2>&1 | tee wget.log || WGET_EXIT=$?
          
          WGET_EXIT=${WGET_EXIT:-0}
          END_TIME=$(date +%s)
          ELAPSED=$((END_TIME - START_TIME))
          
          echo "wget_status=$WGET_EXIT" >> $GITHUB_OUTPUT
          echo "elapsed_time=$ELAPSED" >> $GITHUB_OUTPUT
          
          if [[ $WGET_EXIT -eq 0 || $WGET_EXIT -eq 8 ]]; then
            echo "‚úÖ Download completed (${ELAPSED}s) - Exit code" "$WGET_EXIT"
          else
            echo "‚ö†Ô∏è Download completed with exit code $WGET_EXIT (${ELAPSED}s)"
          fi

      - name: Verify archive
        id: verify
        env:
          OUTPUT_DIR: ${{ steps.validate.outputs.output_dir }}
        run: |
          set -e

          if [ ! -d "$OUTPUT_DIR" ] || [ -z "$(ls -A "$OUTPUT_DIR" 2>/dev/null)" ]; then
            echo "‚ùå Archive is empty or doesn't exist"
            exit 1
          fi

          # Check HTML count
          HTML_COUNT=$(find "$OUTPUT_DIR" -type f \( -name "*.html" -o -name "*.htm" \) | wc -l)
          if [ "$HTML_COUNT" -lt 1 ]; then
            echo "‚ùå No HTML files found"
            exit 1
          fi
          
          # Check minimum size (10KB)
          TOTAL_SIZE=$(du -sb "$OUTPUT_DIR" | cut -f1)
          if [ "$TOTAL_SIZE" -lt 10240 ]; then
            echo "‚ùå Archive too small: $TOTAL_SIZE bytes"
            exit 1
          fi

          FILE_COUNT=$(find "$OUTPUT_DIR" -type f | wc -l)
          DIR_SIZE=$(du -sh "$OUTPUT_DIR" | cut -f1)
          
          echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
          echo "dir_size=$DIR_SIZE" >> $GITHUB_OUTPUT
          echo "html_count=$HTML_COUNT" >> $GITHUB_OUTPUT
          echo "upload_path=$OUTPUT_DIR" >> $GITHUB_OUTPUT
          
          echo "üì¶ Archive verified" "$FILE_COUNT files ($HTML_COUNT HTML) | $DIR_SIZE"
          find "$OUTPUT_DIR" -type f | head -20

      - name: Upload artifact
        id: upload
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}
          path: ${{ steps.verify.outputs.upload_path }}
          retention-days: 30
          if-no-files-found: warn
          compression-level: 0

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: wget-logs-${{ github.run_id }}
          path: wget.log
          retention-days: 7
          if-no-files-found: ignore

      - name: Job summary
        if: always()
        run: |
          echo "## üìä Download Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ steps.validate.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "- Depth: ${{ steps.validate.outputs.depth_level }} (${{ steps.validate.outputs.level_description }})" >> $GITHUB_STEP_SUMMARY
          echo "- Output: ${{ steps.validate.outputs.output_dir }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ -n "${{ steps.verify.outputs.file_count }}" ]]; then
            echo "**Status: ‚úÖ SUCCESS**" >> $GITHUB_STEP_SUMMARY
            echo "- Files: ${{ steps.verify.outputs.file_count }} (${{ steps.verify.outputs.html_count }} HTML)" >> $GITHUB_STEP_SUMMARY
            echo "- Size: ${{ steps.verify.outputs.dir_size }}" >> $GITHUB_STEP_SUMMARY
            echo "- Time: ${{ steps.download.outputs.elapsed_time }}s" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Status: ‚ùå FAILED** (no archive created)" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Artifact:** \`${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}\`" >> $GITHUB_STEP_SUMMARY

      - name: Send callback to N8N
        if: always() && github.event.inputs.resumeUrl
        continue-on-error: true
        run: |
          FILES="${{ steps.verify.outputs.file_count || 0 }}"
          SIZE="${{ steps.verify.outputs.dir_size || 'unknown' }}"
          TIME="${{ steps.download.outputs.elapsed_time || 0 }}"
          STATUS="success"
          
          if [ -z "$FILES" ] || [ "$FILES" = "0" ]; then
            STATUS="failed"
          fi
          
          # Retry logic (3 attempts)
          for i in {1..3}; do
            if curl -s --max-time 10 -X POST "${{ github.event.inputs.resumeUrl }}" \
              -H "Content-Type: application/json" \
              -d "{
                \"status\": \"$STATUS\",
                \"files\": $FILES,
                \"size\": \"$SIZE\",
                \"url\": \"${{ steps.validate.outputs.url }}\",
                \"depth\": ${{ steps.validate.outputs.depth_level }},
                \"time\": $TIME,
                \"run_id\": \"${{ github.run_id }}\",
                \"artifact_name\": \"${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}\"
              }"; then
              echo "‚úÖ Callback sent (attempt $i)"
              break
            else
              echo "‚ö†Ô∏è Callback attempt $i failed"
              [ $i -lt 3 ] && sleep 2
            fi
          done
