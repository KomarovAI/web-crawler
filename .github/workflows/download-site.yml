name: Download Site with Wget

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Website URL to download (https://example.com)'
        required: true
        type: string
      output_dir:
        description: 'Output directory (default: site_archive)'
        required: false
        type: string
        default: 'site_archive'
      max_pages:
        description: 'Max pages to crawl (default: 500)'
        required: false
        type: string
        default: '500'
      use_selenium:
        description: 'Use Selenium (default: false)'
        required: false
        type: string
        default: 'false'
      useSelenium:
        description: 'Use Selenium - alternative name (default: false)'
        required: false
        type: string
        default: 'false'
      ignore_robots:
        description: 'Ignore robots.txt (default: true)'
        required: false
        type: string
        default: 'true'
      ignoreRobots:
        description: 'Ignore robots.txt - alternative name (default: true)'
        required: false
        type: string
        default: 'true'
      resumeUrl:
        description: 'n8n callback webhook URL (optional)'
        required: false
        type: string
        default: ''

permissions:
  contents: read
  actions: read

jobs:
  download-site:
    name: Download Website Archive
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install wget
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget --version | head -1

      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Validate and prepare inputs
        id: validate
        run: |
          # Handle both naming conventions (snake_case and camelCase)
          URL="${{ github.event.inputs.url }}"
          OUTPUT_DIR="${{ github.event.inputs.output_dir }}"
          USE_SELENIUM="${{ github.event.inputs.use_selenium || github.event.inputs.useSelenium }}"
          IGNORE_ROBOTS="${{ github.event.inputs.ignore_robots || github.event.inputs.ignoreRobots }}"
          
          # Apply defaults
          URL=${URL:-"https://callmedley.com"}
          OUTPUT_DIR=${OUTPUT_DIR:-"site_archive"}
          USE_SELENIUM=${USE_SELENIUM:-"false"}
          IGNORE_ROBOTS=${IGNORE_ROBOTS:-"true"}
          
          # Validate URL
          if [[ ! "$URL" =~ ^https?:// ]]; then
            echo "❌ Error: URL must start with http:// or https://"
            exit 1
          fi
          
          # Sanitize directory name
          SANITIZED_DIR=$(echo "$OUTPUT_DIR" | tr -cd '[:alnum:]_-')
          
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "output_dir=$SANITIZED_DIR" >> $GITHUB_OUTPUT
          echo "use_selenium=$USE_SELENIUM" >> $GITHUB_OUTPUT
          echo "ignore_robots=$IGNORE_ROBOTS" >> $GITHUB_OUTPUT
          
          echo "✅ Inputs validated:"
          echo "   URL: $URL"
          echo "   Output Dir: $SANITIZED_DIR"
          echo "   Use Selenium: $USE_SELENIUM"
          echo "   Ignore robots.txt: $IGNORE_ROBOTS"

      - name: Download website with wget
        id: download
        run: |
          python3 crawler.py "${{ steps.validate.outputs.url }}" "${{ steps.validate.outputs.output_dir }}"

      - name: Verify archive
        id: verify
        run: |
          OUTPUT_DIR="${{ steps.validate.outputs.output_dir }}"
          DOMAIN=$(echo "${{ steps.validate.outputs.url }}" | sed -E 's|^https?://||' | sed -E 's|/.*||')
          ARCHIVE_PATH="$OUTPUT_DIR/$DOMAIN"
          
          if [ ! -d "$ARCHIVE_PATH" ] || [ -z "$(ls -A "$ARCHIVE_PATH" 2>/dev/null)" ]; then
            echo "❌ ERROR: Archive is empty or missing: $ARCHIVE_PATH"
            exit 1
          fi
          
          FILE_COUNT=$(find "$ARCHIVE_PATH" -type f | wc -l)
          DIR_SIZE=$(du -sh "$ARCHIVE_PATH" | cut -f1)
          
          echo "✅ Archive verified successfully!"
          echo "   Files: $FILE_COUNT"
          echo "   Size: $DIR_SIZE"
          
          echo "upload_path=$ARCHIVE_PATH" >> $GITHUB_OUTPUT
          echo "file_count=$FILE_COUNT" >> $GITHUB_OUTPUT
          echo "dir_size=$DIR_SIZE" >> $GITHUB_OUTPUT

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.validate.outputs.output_dir }}-${{ github.run_id }}
          path: ${{ steps.verify.outputs.upload_path }}
          retention-days: 30
          compression-level: 6
          if-no-files-found: error

      - name: Create summary
        if: always()
        run: |
          echo "## ✅ Download Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Item | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **URL** | ${{ steps.validate.outputs.url }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Files** | ${{ steps.verify.outputs.file_count }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Size** | ${{ steps.verify.outputs.dir_size }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Status** | ✅ Success |" >> $GITHUB_STEP_SUMMARY

      - name: Send n8n callback
        if: always() && github.event.inputs.resumeUrl != ''
        continue-on-error: true
        run: |
          RESUME_URL="${{ github.event.inputs.resumeUrl }}"
          if [ -n "$RESUME_URL" ]; then
            curl -X POST "$RESUME_URL" \
              -H "Content-Type: application/json" \
              -d "{\"status\":\"${{ job.status }}\",\"run_id\":\"${{ github.run_id }}\",\"files\":\"${{ steps.verify.outputs.file_count }}\",\"size\":\"${{ steps.verify.outputs.dir_size }}\"}" \
              --retry 3 || true
          fi
