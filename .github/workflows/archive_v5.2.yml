name: Archive v5.2 (WARC + robots.txt + media)

on:
  workflow_dispatch:
    inputs:
      url:
        description: 'Start URL (must be valid http/https URL)'
        required: true
        default: 'https://callmedley.com'
      max_pages:
        description: 'Max pages to crawl (1-5000)'
        required: true
        default: '500'
      use_selenium:
        description: 'Use Selenium for Cloudflare'
        required: false
        default: 'true'
      target_repo:
        description: 'Target repository for deployment (format: owner/repo, leave empty to skip)'
        required: false
        default: ''
      reuse_artifact_run_id:
        description: 'Reuse artifact from previous run (leave empty to crawl now, or enter run ID)'
        required: false
        default: ''

permissions:
  contents: read
  id-token: write
  actions: read

jobs:
  validate-inputs:
    name: Validate workflow inputs
    runs-on: ubuntu-24.04
    outputs:
      domain: ${{ steps.validate.outputs.domain }}
      max_pages: ${{ steps.validate.outputs.max_pages }}
      target_repo: ${{ steps.validate.outputs.target_repo }}
      reuse_mode: ${{ steps.validate.outputs.reuse_mode }}
      reuse_run_id: ${{ steps.validate.outputs.reuse_run_id }}
    steps:
      - name: Validate and sanitize inputs
        id: validate
        run: |
          URL="${{ github.event.inputs.url }}"
          REUSE_RUN_ID="${{ github.event.inputs.reuse_artifact_run_id }}"
          
          if [ -n "$REUSE_RUN_ID" ]; then
            echo "reuse_mode=true" >> $GITHUB_OUTPUT
            echo "reuse_run_id=$REUSE_RUN_ID" >> $GITHUB_OUTPUT
            echo "‚úÖ Reuse mode: Using artifact from run #$REUSE_RUN_ID (skip crawling)"
            echo "domain=" >> $GITHUB_OUTPUT
            echo "max_pages=" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "reuse_mode=false" >> $GITHUB_OUTPUT
          
          if [[ ! "$URL" =~ ^https?:// ]]; then
            echo "‚ùå Error: URL must start with http:// or https://"
            exit 1
          fi
          DOMAIN=$(echo "$URL" | sed -E 's|^https?://||' | sed -E 's|/.*||' | cut -d'?' -f1)
          if [[ -z "$DOMAIN" ]]; then
            echo "‚ùå Error: Invalid domain"
            exit 1
          fi
          MAX_PAGES="${{ github.event.inputs.max_pages }}"
          if ! [[ "$MAX_PAGES" =~ ^[0-9]+$ ]] || (( MAX_PAGES < 1 || MAX_PAGES > 5000 )); then
            echo "‚ùå Error: max_pages must be 1-5000"
            exit 1
          fi
          TARGET_REPO="${{ github.event.inputs.target_repo }}"
          if [ -n "$TARGET_REPO" ]; then
            if [[ ! "$TARGET_REPO" =~ ^[a-zA-Z0-9_-]+/[a-zA-Z0-9_.-]+$ ]]; then
              echo "‚ùå Error: Invalid target_repo format"
              exit 1
            fi
          fi
          echo "domain=$DOMAIN" >> $GITHUB_OUTPUT
          echo "max_pages=$MAX_PAGES" >> $GITHUB_OUTPUT
          echo "target_repo=$TARGET_REPO" >> $GITHUB_OUTPUT
          echo "‚úÖ Validation passed: $DOMAIN"

  archive:
    name: Archive website (crawl mode)
    runs-on: ubuntu-24.04
    timeout-minutes: 120
    needs: validate-inputs
    if: needs.validate-inputs.outputs.reuse_mode == 'false'
    permissions:
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create .env
        run: |
          python3 << 'PYTHON'
          url = '${{ github.event.inputs.url }}'
          max_pages = '${{ needs.validate-inputs.outputs.max_pages }}'
          domain = '${{ needs.validate-inputs.outputs.domain }}'
          with open('.env', 'w') as f:
              f.write(f"STARTURL={url}\n")
              f.write(f"MAXPAGES={max_pages}\n")
          with open('domain.txt', 'w') as f:
              f.write(domain)
          print(f"CONFIG: {url}, {max_pages}, {domain}")
          PYTHON
      
      - name: Display configuration
        run: |
          cat .env
          source .env
          echo "Starting ArchiveBot v5.2"
          echo "URL: $STARTURL"
          echo "MAXPAGES: $MAXPAGES"
      
      - name: Run ArchiveBot v5.2
        run: |
          source .env
          python3 smart_archiver_v4.py "$STARTURL" "$MAXPAGES"
        env:
          USE_SELENIUM: ${{ github.event.inputs.use_selenium }}
      
      - name: Generate report
        if: always()
        run: |
          python3 << 'PYTHON'
          import sqlite3
          from pathlib import Path
          domain = open('domain.txt').read().strip()
          archive_dir = f"archive_{domain.replace('.', '_')}"
          db_path = f"{archive_dir}/{domain.replace('.', '_')}.db"
          if not Path(db_path).exists():
              print("No database found")
          else:
              conn = sqlite3.connect(db_path)
              cursor = conn.cursor()
              cursor.execute('SELECT COUNT(*) FROM pages')
              pages = cursor.fetchone()[0]
              cursor.execute('SELECT COUNT(*) FROM error_log')
              errors = cursor.fetchone()[0]
              print(f"Archive Report: Pages={pages}, Errors={errors}")
              conn.close()
          PYTHON
      
      - name: Upload archive artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: archive-${{ github.run_id }}
          path: archive_*/
          retention-days: 90
          compression-level: 6
      
      - name: Create job summary
        if: always()
        run: |
          echo "## ‚úÖ ArchiveBot v5.2 Complete (Crawl Mode)" >> $GITHUB_STEP_SUMMARY
          echo "- **URL**: ${{ github.event.inputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Max Pages**: ${{ needs.validate-inputs.outputs.max_pages }}" >> $GITHUB_STEP_SUMMARY

  reuse-artifact:
    name: Reuse artifact from previous run
    runs-on: ubuntu-24.04
    needs: validate-inputs
    if: needs.validate-inputs.outputs.reuse_mode == 'true'
    permissions:
      actions: read
      contents: read
    steps:
      - name: Validate run ID
        id: validate_run
        run: |
          RUN_ID="${{ needs.validate-inputs.outputs.reuse_run_id }}"
          if ! [[ "$RUN_ID" =~ ^[0-9]+$ ]]; then
            echo "‚ùå Error: Invalid run ID format (must be numeric)"
            exit 1
          fi
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
          echo "‚úÖ Using artifact from run #$RUN_ID"
      
      - name: Download artifact from previous run
        uses: actions/download-artifact@v4
        with:
          name: archive-${{ steps.validate_run.outputs.run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          repository: ${{ github.repository }}
          run-id: ${{ steps.validate_run.outputs.run_id }}
      
      - name: Extract domain from artifact
        id: extract_domain
        run: |
          ARCHIVE_DIR=$(find . -maxdepth 2 -name "archive_*" -type d | head -1)
          if [ -z "$ARCHIVE_DIR" ]; then
            echo "‚ùå Error: No archive found in artifact"
            ls -la
            exit 1
          fi
          ARCHIVE_DIR="${ARCHIVE_DIR#./}"
          echo "archive_dir=$ARCHIVE_DIR" >> $GITHUB_OUTPUT
          echo "‚úÖ Found archive: $ARCHIVE_DIR"
      
      - name: Upload reused artifact
        uses: actions/upload-artifact@v4
        with:
          name: archive-${{ github.run_id }}
          path: ${{ steps.extract_domain.outputs.archive_dir }}/
          retention-days: 90
      
      - name: Create job summary
        run: |
          echo "## ‚ôªÔ∏è Reuse Mode - Previous Run Artifact" >> $GITHUB_STEP_SUMMARY
          echo "- **Source Run ID**: ${{ needs.validate-inputs.outputs.reuse_run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Archive**: ${{ steps.extract_domain.outputs.archive_dir }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Crawling**: ‚è≠Ô∏è SKIPPED" >> $GITHUB_STEP_SUMMARY

  deploy:
    name: Deploy to external repository (ROOT)
    runs-on: ubuntu-24.04
    needs: [validate-inputs, archive, reuse-artifact]
    if: always() && (needs.archive.result == 'success' || needs.reuse-artifact.result == 'success')
    permissions:
      contents: read
    environment:
      name: external-deployment
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: archive-${{ github.run_id }}
          path: ./archive_download

      - name: Extract domain from artifact
        id: get_domain
        run: |
          ARCHIVE_DIR=$(find archive_download -maxdepth 2 -name "archive_*" -type d | head -1)
          if [ -z "$ARCHIVE_DIR" ]; then
            echo "‚ùå Error: No archive found"
            echo "Contents of archive_download:"
            ls -la archive_download/
            exit 1
          fi
          DOMAIN=$(basename "$ARCHIVE_DIR" | sed 's/archive_//' | sed 's/_/./g')
          echo "domain=$DOMAIN" >> $GITHUB_OUTPUT
          echo "archive_path=$ARCHIVE_DIR" >> $GITHUB_OUTPUT
          echo "‚úÖ Found archive: $ARCHIVE_DIR (domain: $DOMAIN)"
      
      - name: Deploy to ROOT (extract contents)
        if: ${{ github.event.inputs.target_repo }}
        env:
          GH_TOKEN: ${{ secrets.EXTERNAL_REPO_PAT }}
          DOMAIN: ${{ steps.get_domain.outputs.domain }}
        run: |
          set -e
          TARGET_REPO="${{ github.event.inputs.target_repo }}"
          ARCHIVE_PATH="${{ steps.get_domain.outputs.archive_path }}"
          
          echo "üöÄ Deploy Archive to ROOT (extracting contents)"
          echo "Target: $TARGET_REPO"
          echo "Domain: $DOMAIN"
          echo "Archive: $ARCHIVE_PATH"
          
          TEMP_DIR=$(mktemp -d)
          cd "$TEMP_DIR"
          
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          echo "üì¶ Cloning $TARGET_REPO"
          git clone --depth 1 "https://oauth2:${GH_TOKEN}@github.com/${TARGET_REPO}.git" . || exit 1
          
          echo "üóëÔ∏è Deleting all existing files except .git"
          find . -type f ! -path './.git*' -delete
          find . -type d ! -path './.git*' -type d -empty -delete
          
          if [ ! -d "$GITHUB_WORKSPACE/$ARCHIVE_PATH" ]; then
            echo "‚ùå Archive not found: $GITHUB_WORKSPACE/$ARCHIVE_PATH"
            ls -la "$GITHUB_WORKSPACE/archive_download/"
            exit 1
          fi
          
          echo "üìÅ Extracting archive contents directly to ROOT..."
          cp -r "$GITHUB_WORKSPACE/$ARCHIVE_PATH"/* . 2>/dev/null || true
          
          echo "üìÅ Removing WARC files (GitHub 100MB limit)"
          find . -name "*.warc" -delete 2>/dev/null || true
          find . -name "*.warc.gz" -delete 2>/dev/null || true
          
          echo "üìÅ Rewriting links to local paths..."
          python3 << 'EOF'
import os
import re
from pathlib import Path
from urllib.parse import urlparse, unquote

def normalize_path(path):
    path = unquote(path)
    path = path.strip('/')
    if not path or path == 'index.html':
        return 'index.html'
    if path.endswith('/'):
        path = path + 'index.html'
    elif not path.endswith('.html') and not '.' in path.split('/')[-1]:
        path = path + '/index.html'
    return path

def should_rewrite_url(url, domain):
    if not url or url.startswith('#') or url.startswith('javascript:') or url.startswith('mailto:') or url.startswith('tel:'):
        return False
    if domain in url:
        return True
    if url.startswith('/'):
        return True
    if not url.startswith('http://') and not url.startswith('https://') and not url.startswith('//'):
        return True
    return False

def rewrite_url(url, domain):
    if not should_rewrite_url(url, domain):
        return url
    
    if f'https://{domain}' in url:
        path = url.split(f'https://{domain}', 1)[1]
    elif f'http://{domain}' in url:
        path = url.split(f'http://{domain}', 1)[1]
    else:
        path = url
    
    path_only = path.split('?')[0].split('#')[0]
    fragment = url.split('#', 1)[1] if '#' in url else ''
    query = '?' + url.split('?', 1)[1] if '?' in url else ''
    
    normalized = normalize_path(path_only)
    result = normalized
    if query:
        result += query
    if fragment:
        result += '#' + fragment
    if result.startswith('/'):
        result = result[1:]
    return result

def process_html_file(filepath, domain):
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
    except Exception as e:
        return False
    
    original_content = content
    patterns = [
        (r'href=["\']([^"\'>]+)["\']', 'href'),
        (r'src=["\']([^"\'>]+)["\']', 'src'),
        (r'action=["\']([^"\'>]+)["\']', 'action'),
    ]
    
    for pattern, attr_type in patterns:
        def replace_url(match):
            url = match.group(1)
            if url.startswith('data:') or url.startswith('blob:'):
                return match.group(0)
            new_url = rewrite_url(url, domain)
            if new_url != url:
                quote = '"' if '"' in match.group(0) else "'"
                attr_name = attr_type.split('-')[0]
                return f'{attr_name}={quote}{new_url}{quote}'
            return match.group(0)
        content = re.sub(pattern, replace_url, content, flags=re.IGNORECASE)
    
    if content != original_content:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    return False

domain = os.environ.get('DOMAIN', 'example.com')
total = 0
modified = 0
for root, dirs, files in os.walk('.'):
    dirs[:] = [d for d in dirs if not d.startswith('.')]
    for file in files:
        if file.lower().endswith('.html'):
            filepath = os.path.join(root, file)
            total += 1
            if process_html_file(filepath, domain):
                modified += 1

print(f"‚úÖ Rewrite complete: {total} HTML files, {modified} modified")
EOF
          
          echo "üìÅ Creating metadata file"
          cat > DEPLOYMENT_INFO.txt << METADATA
Source: ${{ github.repository }}
Run: ${{ github.run_id }}
Time: $(date)
Deployed to: ROOT (GitHub Pages direct)
Link Rewriting: YES - All absolute URLs converted to relative paths
Note: WARC files excluded due to GitHub 100MB limit
METADATA
          
          git add -A
          
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "chore: Deploy archive to ROOT - $(date +%Y-%m-%d) - Links rewritten"
            git push origin HEAD:main --force 2>/dev/null || git push origin HEAD:master --force
            echo "‚úÖ Successfully deployed to ROOT with rewritten links!"
          else
            echo "‚ö†Ô∏è No changes detected"
          fi

      - name: Summary
        if: always()
        run: |
          echo "## üöÄ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -z "${{ github.event.inputs.target_repo }}" ]; then
            echo "‚è≠Ô∏è **Skipped**: No target_repo specified" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚úÖ **Target**: ${{ github.event.inputs.target_repo }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**GitHub Pages URL**: https://$(echo ${{ github.event.inputs.target_repo }} | cut -d'/' -f1).github.io/$(echo ${{ github.event.inputs.target_repo }} | cut -d'/' -f2)/" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Link Rewriting**: ‚úÖ All absolute URLs converted to relative paths" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Location**: ROOT (GitHub Pages)" >> $GITHUB_STEP_SUMMARY
