# Web Crawler Configuration

# Target URL to start crawling from
START_URL=https://example.com

# Maximum number of pages to crawl
MAX_PAGES=50

# Request timeout in seconds
TIMEOUT_SECONDS=30

# Rate limiting: requests per second
# Recommended: 1.0-3.0 (respect server resources)
RATE_LIMIT_PER_SEC=2.0

# Maximum retry attempts for failed requests
MAX_RETRIES=3

# Retry backoff factor (exponential: 2^attempt)
RETRY_BACKOFF_FACTOR=2.0

# Database settings
DB_FILE=crawler.db
USE_DB=true
ENABLE_DB=true

# Logging
LOG_LEVEL=INFO
LOG_FILE=crawler.log

# Connection pooling
CONN_LIMIT_PER_HOST=2
CONN_LIMIT_TOTAL=10
